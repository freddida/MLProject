{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NO PCA and no NaN imputing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9319ebdf53bd2c2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdcebb0d81661834"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.utils.filtering import filter_data\n",
    "from src.utils.data_loading import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils.label_encoding import label_encode_column\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:49:10.815225931Z",
     "start_time": "2024-01-28T13:49:03.375554117Z"
    }
   },
   "id": "f195c7b9f22f87ca",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"geocentric_latitude\",  # Latitude of conjunction point [deg]\n",
    "    \"c_sigma_rdot\",  # covariance; radial velocity standard deviation (sigma) of chaser [m/s]\n",
    "    \"c_obs_used\",  # number of observations used for orbit determination (per CDM) of chaser\n",
    "    \"c_time_lastob_start\",\n",
    "    # start of the time in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"c_time_lastob_end\",\n",
    "    # end of the time interval in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"mahalanobis_distance\",  # The distance between the chaser and target\n",
    "    \"miss_distance\",  # relative position between chaser & target at tca [m\n",
    "    \"time_to_tca\",  # Time interval between CDM creation and time-of-closest approach [days]\n",
    "    \"t_cndot_r\",\n",
    "    # covariance; correlation of normal (cross-track) velocity vs radial position of chaser\n",
    "    \"c_cr_area_over_mass\",\n",
    "    # solar radiation coefficient . A/m (ballistic coefficient equivalent) of chaser\n",
    "    \"max_risk_estimate\",  # maximum collision probability obtained by scaling combined covariance\n",
    "    \"c_span\",  # size used by the collision risk computation algorithm of chaser [m]\n",
    "    \"max_risk_scaling\",  # scaling factor used to compute maximum collision probability\n",
    "    \"t_rcs_estimate\",  # radar cross-sectional area [m2m2] of target\n",
    "    \"c_sigma_t\",\n",
    "    # covariance; transverse (along-track) position standard deviation (sigma) of chaser [m]\n",
    "    \"c_obs_available\",  # number of observations available for orbit determination (per CDM),\n",
    "    \"risk\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:49:15.833494107Z",
     "start_time": "2024-01-28T13:49:15.750562834Z"
    }
   },
   "id": "4e7a33d4ec2f8a1a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162634 entries, 0 to 162633\n",
      "Columns: 103 entries, event_id to AP\n",
      "dtypes: float64(98), int64(4), object(1)\n",
      "memory usage: 127.8+ MB\n",
      "Filtered data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Columns: 103 entries, event_id to AP\n",
      "dtypes: float64(98), int64(4), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "(3032, 17)\n",
      "Full Training set shape: (2425, 16) (2425,)\n",
      "Testing set shape: (607, 16) (607,)\n",
      "Training set shape: (1818, 16) (1818,)\n",
      "Validation set shape: (607, 16) (607,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "nan = np.nan\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        return []\n",
    "\n",
    "# Load and data and filter it\n",
    "df = load_data()\n",
    "df_filtered = filter_data(df)\n",
    "\n",
    "\n",
    "\n",
    "# Remove rows with missing values\n",
    "#df_filtered.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "#print(\"hi\")\n",
    "\n",
    "\n",
    "# Label encode the categorical column \"c_object_type\"\n",
    "label_encode_column(df_filtered, \"c_object_type\")\n",
    "\n",
    "\n",
    "# Call the function to get the processed DataFrame\n",
    "df_processed = df_filtered[selected_features]\n",
    "arr_processed = df_processed.to_numpy()\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "arr_imputed=imputer.fit_transform(arr_processed)\n",
    "#print(arr_imputed.shape)\n",
    "df_imputed = pd.DataFrame(data=arr_imputed[0:,0:],index=[i for i in range(arr_imputed.shape[0])],columns=selected_features)\n",
    "# Separate features and target variable\n",
    "X = df_imputed.drop('risk', axis=1)\n",
    "y = df_imputed['risk']\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "# Perform scaling after splitting the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same scaler to the validation and test sets\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the sets\n",
    "print(\"Full Training set shape:\", X_train_full.shape, y_train_full.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Training set shape:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val_scaled.shape, y_val.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T13:51:34.019162544Z",
     "start_time": "2024-01-28T13:51:26.096897366Z"
    }
   },
   "id": "7b5cf00d03a05bc2",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Added the KNNI imputer in the above cell."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5266ea9a9ff8ede5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5010e4803236611"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose Models\n",
    "models = {\n",
    "    # 'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in param_grid:\n",
    "        # Use GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid[model_name], scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "    else:\n",
    "        # For models without hyperparameters, use the default configuration\n",
    "        best_models[model_name] = model.fit(X_train_scaled, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-28T13:55:30.808151086Z"
    }
   },
   "id": "c8cb6fecba86b0fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8576841ab973e7ba"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MSE on training set: 0.029886637427188643\n",
      "Random Forest - MSE on validation set: 0.09465651937298585\n"
     ]
    }
   ],
   "source": [
    "# Train Models\n",
    "for model_name, model in best_models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate on training set\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    print(f'{model_name} - MSE on training set: {mse_train}')\n",
    "\n",
    "# Evaluate on validation set\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    print(f'{model_name} - MSE on validation set: {mse_val}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T15:17:04.330040323Z",
     "start_time": "2024-01-24T15:17:01.609307633Z"
    }
   },
   "id": "9cd71e1565519fe3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on training set: 16.625454950015342\n",
      "MAE on validation set: 16.258605110271596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/ML_project/MLProject/venv/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/leo/ML_project/MLProject/venv/lib/python3.8/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming y_pred is your predicted values and y_true is the true target values\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculate MAE for training set\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculate MAE for validation set\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "\n",
    "# Print the MAE values\n",
    "print(f\"MAE on training set: {mae_train}\")\n",
    "print(f\"MAE on validation set: {mae_val}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T15:17:22.797991331Z",
     "start_time": "2024-01-24T15:17:22.664742360Z"
    }
   },
   "id": "a636ae0b9a276ba2",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared on training set: -4.119008021062443\n",
      "R-squared on validation set: -3.7891234703833687\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared for training set\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# Calculate R-squared for validation set\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "# Print the R-squared values\n",
    "print(f\"R-squared on training set: {r2_train}\")\n",
    "print(f\"R-squared on validation set: {r2_val}\")\n",
    "print(\"hi\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T15:17:38.676234052Z",
     "start_time": "2024-01-24T15:17:38.661594768Z"
    }
   },
   "id": "618ddf16e338f44e",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Comparison:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c811ee014d45e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfdd236370a7ebb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9847126743e566"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7789fbee6c9da9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

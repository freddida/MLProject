{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NO PCA and no NaN imputing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9319ebdf53bd2c2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdcebb0d81661834"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.utils.filtering import filter_data\n",
    "from src.utils.data_loading import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils.label_encoding import label_encode_column\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f195c7b9f22f87ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"geocentric_latitude\",  # Latitude of conjunction point [deg]\n",
    "    \"c_sigma_rdot\",  # covariance; radial velocity standard deviation (sigma) of chaser [m/s]\n",
    "    \"c_obs_used\",  # number of observations used for orbit determination (per CDM) of chaser\n",
    "    \"c_time_lastob_start\",\n",
    "    # start of the time in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"c_time_lastob_end\",\n",
    "    # end of the time interval in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"mahalanobis_distance\",  # The distance between the chaser and target\n",
    "    \"miss_distance\",  # relative position between chaser & target at tca [m\n",
    "    \"time_to_tca\",  # Time interval between CDM creation and time-of-closest approach [days]\n",
    "    \"t_cndot_r\",\n",
    "    # covariance; correlation of normal (cross-track) velocity vs radial position of chaser\n",
    "    \"c_cr_area_over_mass\",\n",
    "    # solar radiation coefficient . A/m (ballistic coefficient equivalent) of chaser\n",
    "    \"max_risk_estimate\",  # maximum collision probability obtained by scaling combined covariance\n",
    "    \"c_span\",  # size used by the collision risk computation algorithm of chaser [m]\n",
    "    \"max_risk_scaling\",  # scaling factor used to compute maximum collision probability\n",
    "    \"t_rcs_estimate\",  # radar cross-sectional area [m2m2] of target\n",
    "    \"c_sigma_t\",\n",
    "    # covariance; transverse (along-track) position standard deviation (sigma) of chaser [m]\n",
    "    \"c_obs_available\",  # number of observations available for orbit determination (per CDM),\n",
    "    \"risk\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7a33d4ec2f8a1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and data and filter it\n",
    "df = load_data()\n",
    "df_filtered = filter_data(df)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_filtered.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# Label encode the categorical column \"c_object_type\"\n",
    "label_encode_column(df_filtered, \"c_object_type\")\n",
    "# Call the function to get the processed DataFrame\n",
    "df_processed = df_filtered[selected_features]\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_processed.drop('risk', axis=1)\n",
    "y = df_processed['risk']\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "# Perform scaling after splitting the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same scaler to the validation and test sets\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the sets\n",
    "print(\"Full Training set shape:\", X_train_full.shape, y_train_full.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "print(\"Training set shape:\", X_train_scaled.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val_scaled.shape, y_val.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5cf00d03a05bc2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5010e4803236611"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose Models\n",
    "models = {\n",
    "    # 'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in param_grid:\n",
    "        # Use GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid[model_name], scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "    else:\n",
    "        # For models without hyperparameters, use the default configuration\n",
    "        best_models[model_name] = model.fit(X_train_scaled, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8cb6fecba86b0fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8576841ab973e7ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train Models\n",
    "for model_name, model in best_models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Evaluate on training set\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    print(f'{model_name} - MSE on training set: {mse_train}')\n",
    "\n",
    "# Evaluate on validation set\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    print(f'{model_name} - MSE on validation set: {mse_val}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd71e1565519fe3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming y_pred is your predicted values and y_true is the true target values\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculate MAE for training set\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculate MAE for validation set\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "\n",
    "# Print the MAE values\n",
    "print(f\"MAE on training set: {mae_train}\")\n",
    "print(f\"MAE on validation set: {mae_val}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a636ae0b9a276ba2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared for training set\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# Calculate R-squared for validation set\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "# Print the R-squared values\n",
    "print(f\"R-squared on training set: {r2_train}\")\n",
    "print(f\"R-squared on validation set: {r2_val}\")\n",
    "print(\"hi\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "618ddf16e338f44e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Comparison:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c811ee014d45e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfdd236370a7ebb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9847126743e566"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7789fbee6c9da9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": ".venv",
   "language": "python",
   "display_name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

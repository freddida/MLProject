{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:09.740169Z",
     "start_time": "2024-01-24T16:07:09.727768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from src.utils.check_mps_device import check_mps_device\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from src.utils.data_loading import load_data\n",
    "from src.utils.filtering import filter_data\n",
    "import seaborn as sns\n",
    "from src.utils.label_encoding import label_encode_column\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Check if PyTorch Multi-Process Service (MPS) is available (GPU)\n",
    "check_mps_device()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"geocentric_latitude\",  # Latitude of conjunction point [deg]\n",
    "    \"c_sigma_rdot\",  # covariance; radial velocity standard deviation (sigma) of chaser [m/s]\n",
    "    \"c_obs_used\",  # number of observations used for orbit determination (per CDM) of chaser\n",
    "    \"c_time_lastob_start\",\n",
    "    # start of the time in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"c_time_lastob_end\",\n",
    "    # end of the time interval in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"mahalanobis_distance\",  # The distance between the chaser and target\n",
    "    \"miss_distance\",  # relative position between chaser & target at tca [m\n",
    "    \"time_to_tca\",  # Time interval between CDM creation and time-of-closest approach [days]\n",
    "    \"t_cndot_r\",\n",
    "    # covariance; correlation of normal (cross-track) velocity vs radial position of chaser\n",
    "    \"c_cr_area_over_mass\",\n",
    "    # solar radiation coefficient . A/m (ballistic coefficient equivalent) of chaser\n",
    "    \"max_risk_estimate\",  # maximum collision probability obtained by scaling combined covariance\n",
    "    \"c_span\",  # size used by the collision risk computation algorithm of chaser [m]\n",
    "    \"max_risk_scaling\",  # scaling factor used to compute maximum collision probability\n",
    "    \"t_rcs_estimate\",  # radar cross-sectional area [m2m2] of target\n",
    "    \"c_sigma_t\",\n",
    "    # covariance; transverse (along-track) position standard deviation (sigma) of chaser [m]\n",
    "    \"c_obs_available\",  # number of observations available for orbit determination (per CDM),\n",
    "    \"risk\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:09.928229Z",
     "start_time": "2024-01-24T16:07:09.922971Z"
    }
   },
   "id": "efaacfa08cb5d5f1",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162634 entries, 0 to 162633\n",
      "Columns: 103 entries, event_id to AP\n",
      "dtypes: float64(98), int64(4), object(1)\n",
      "memory usage: 127.8+ MB\n",
      "Filtered data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Columns: 103 entries, event_id to AP\n",
      "dtypes: float64(98), int64(4), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load and data and filter it\n",
    "df = load_data()\n",
    "df_filtered = filter_data(df)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_filtered.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# Label encode the categorical column \"c_object_type\"\n",
    "label_encode_column(df_filtered, \"c_object_type\")\n",
    "\n",
    "# Call the function to get the processed DataFrame\n",
    "df_processed = df_filtered[selected_features]\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_processed.drop('risk', axis=1) # features (17)\n",
    "y = df_processed['risk'] # target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:12.666278Z",
     "start_time": "2024-01-24T16:07:10.090435Z"
    }
   },
   "id": "fd101080fa6f3345",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058, 16)\n",
      "(1058,)\n",
      "(265, 16)\n",
      "(265,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train_class = np.where(y >= -6,1,0)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y_train_class)\n",
    "# \n",
    "# X_train, X_val, y_train_real, y_val_real = train_test_split(X_t, y_t_real, \n",
    "#                                                             test_size=0.20, \n",
    "#                                                             random_state=21,  \n",
    "#                                                             shuffle=True,\n",
    "#                                                             stratify=y_t_class)\n",
    "# \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:12.674797Z",
     "start_time": "2024-01-24T16:07:12.664494Z"
    }
   },
   "id": "5148189349077432",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "907df8d4451829b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SMOTE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1187a18766ac3523"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1962, 16)\n",
      "(1962,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE to the training data to balance the classes\n",
    "y_train = np.where(y_train>= -6, 1,0)\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=20)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# y_train_resampled = y_train.reshape(-1, 1)\n",
    "print(X_train_resampled.shape)\n",
    "print(y_train_resampled.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:12.683028Z",
     "start_time": "2024-01-24T16:07:12.671359Z"
    }
   },
   "id": "af3e8e5105f8a454",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set shape: (265, 16) (265,)\n",
      "Training set shape: (1962, 16) (1962,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Perform scaling after splitting the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "X_train_final = scaler.fit_transform(X_train_resampled)\n",
    "y_train_final = y_train_resampled\n",
    "\n",
    "\n",
    "# Apply the same scaler to the validation and test sets\n",
    "\n",
    "X_test_final = scaler.transform(X_test)\n",
    "y_test_final = y_test\n",
    "# # Display the shapes of the sets\n",
    "print(\"Testing set shape:\", X_test_final.shape, y_test_final.shape)\n",
    "print(\"Training set shape:\", X_train_final.shape, y_train_final.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:07:12.719357Z",
     "start_time": "2024-01-24T16:07:12.686034Z"
    }
   },
   "id": "3351adb4efae986c",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cc6da3b1416d044"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose Models\n",
    "models = {\n",
    "    # 'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    # 'Random Forest': {\n",
    "    #     'n_estimators': [50, 100, 200],\n",
    "    #     'max_depth': [None, 10, 20],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4]\n",
    "    # }\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10, ],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name in param_grid:\n",
    "        # Use GridSearchCV for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grid[model_name], scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train_final, y_train_final)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "    else:\n",
    "        # For models without hyperparameters, use the default configuration\n",
    "        best_models[model_name] = model.fit(X_train_final, y_train_final)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:08:10.439607Z",
     "start_time": "2024-01-24T16:07:12.698133Z"
    }
   },
   "id": "cbda91954976dd80",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae636870c441aef4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train Models\n",
    "for model_name, model in best_models.items():\n",
    "    model.fit(X_train_final, y_train_final)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:08:11.090007Z",
     "start_time": "2024-01-24T16:08:10.440860Z"
    }
   },
   "id": "d74f7f2dbb0928ec",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Evaluate Performance\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# \n",
    "# # Evaluate on training set\n",
    "# for model_name, model in best_models.items():\n",
    "#     y_pred_train = model.predict(X_train_final)\n",
    "#     mse_train = mean_squared_error(y_train_final, y_pred_train)\n",
    "#     print(f'{model_name} - MSE on training set: {mse_train}')\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e95ab363ec9c7de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1962, 16)\n",
      "(1962,)\n",
      "(1962,)\n",
      "(265,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1962, 265]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(y_pred\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(y_test\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_final\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(x)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(x)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    213\u001B[0m     ):\n\u001B[0;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    224\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1239\u001B[0m, in \u001B[0;36mf1_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1071\u001B[0m     {\n\u001B[1;32m   1072\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1098\u001B[0m ):\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \n\u001B[1;32m   1101\u001B[0m \u001B[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001B[39;00m\n\u001B[1;32m   1238\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfbeta_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1240\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1241\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1245\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1246\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:187\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1413\u001B[0m, in \u001B[0;36mfbeta_score\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1251\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1252\u001B[0m     {\n\u001B[1;32m   1253\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1280\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1281\u001B[0m ):\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F-beta score.\u001B[39;00m\n\u001B[1;32m   1283\u001B[0m \n\u001B[1;32m   1284\u001B[0m \u001B[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1410\u001B[0m \u001B[38;5;124;03m    0.38...\u001B[39;00m\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1413\u001B[0m     _, _, f, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1414\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1415\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1419\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf-score\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1421\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:187\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1724\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1566\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[1;32m   1567\u001B[0m \n\u001B[1;32m   1568\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1721\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[1;32m   1722\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1723\u001B[0m zero_division_value \u001B[38;5;241m=\u001B[39m _check_zero_division(zero_division)\n\u001B[0;32m-> 1724\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1726\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1727\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1501\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1499\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[0;32m-> 1501\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_targets\u001B[39m(y_true, y_pred):\n\u001B[1;32m     58\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \n\u001B[1;32m     60\u001B[0m \u001B[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;124;03m    y_pred : array or indicator matrix\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m     \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m     type_true \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     86\u001B[0m     type_pred \u001B[38;5;241m=\u001B[39m type_of_target(y_pred, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    405\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 407\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    408\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    409\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    410\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [1962, 265]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "x = {}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_train = model.predict(X_train_final)\n",
    "    print(X_train_final.shape)\n",
    "    print(y_pred_train.shape)\n",
    "    y_pred = np.where(y_pred_train >= -6, -5, -6.00001)\n",
    "    print(y_pred.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    x = f1_score(y_pred, y_test_final)\n",
    "    \n",
    "score = max(x)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T16:26:51.251015Z",
     "start_time": "2024-01-24T16:26:51.108397Z"
    }
   },
   "id": "32d5e9220c584919",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95258cf4f3e36f02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

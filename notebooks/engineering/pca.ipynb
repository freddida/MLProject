{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PCA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c857fc5ed2d73d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.utils.check_mps_device import check_mps_device\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from src.utils.data_loading import load_data\n",
    "from src.utils.filtering import filter_data\n",
    "from src.utils.label_encoding import label_encode_column\n",
    "\n",
    "# Check if PyTorch Multi-Process Service (MPS) is available (GPU)\n",
    "check_mps_device()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "178275266ff85e96",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \"geocentric_latitude\",  # Latitude of conjunction point [deg]\n",
    "    \"c_sigma_rdot\",  # covariance; radial velocity standard deviation (sigma) of chaser [m/s]\n",
    "    \"c_obs_used\",  # number of observations used for orbit determination (per CDM) of chaser\n",
    "    \"c_time_lastob_start\",\n",
    "    # start of the time in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"c_time_lastob_end\",\n",
    "    # end of the time interval in days of the last accepted observation used in the orbit determination of chaser\n",
    "    \"mahalanobis_distance\",  # The distance between the chaser and target\n",
    "    \"miss_distance\",  # relative position between chaser & target at tca [m\n",
    "    \"time_to_tca\",  # Time interval between CDM creation and time-of-closest approach [days]\n",
    "    \"t_cndot_r\",\n",
    "    # covariance; correlation of normal (cross-track) velocity vs radial position of chaser\n",
    "    \"c_cr_area_over_mass\",\n",
    "    # solar radiation coefficient . A/m (ballistic coefficient equivalent) of chaser\n",
    "    \"max_risk_estimate\",  # maximum collision probability obtained by scaling combined covariance\n",
    "    \"c_span\",  # size used by the collision risk computation algorithm of chaser [m]\n",
    "    \"max_risk_scaling\",  # scaling factor used to compute maximum collision probability\n",
    "    \"t_rcs_estimate\",  # radar cross-sectional area [m2m2] of target\n",
    "    \"c_sigma_t\",\n",
    "    # covariance; transverse (along-track) position standard deviation (sigma) of chaser [m]\n",
    "    \"c_obs_available\",  # number of observations available for orbit determination (per CDM),\n",
    "    \"risk\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0bcc1d2bd4f3ead",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Scaling:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12081f9b59f6439d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and data and filter it\n",
    "df = load_data()\n",
    "df_filtered = filter_data(df)\n",
    "df_filtered.dropna(axis=0, how=\"any\", inplace=True)\n",
    "# Label encode the categorical column \"c_object_type\"\n",
    "label_encode_column(df_filtered, \"c_object_type\")\n",
    "\n",
    "df_new = df_filtered[selected_features]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2031a1c426e843",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical features\n",
    "numerical_features = df_new.select_dtypes(include=[\"float64\"]).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_new_scaled = df_new.copy()\n",
    "# Scale numerical features\n",
    "df_new_scaled[numerical_features] = scaler.fit_transform(\n",
    "    df_new_scaled[numerical_features]\n",
    ")\n",
    "\n",
    "# Optionally, you can display the summary statistics of the scaled features\n",
    "# print(\"Summary statistics after scaling:\")\n",
    "# print(df_new_scaled[numerical_features].describe())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "373d60357fac1188",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the already selected 17 features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4df203d8e005eab3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# a. Confirm Relevant Features:\n",
    "# Display the selected 17 features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Verify that these features align with the problem statement and provide meaningful information\n",
    "\n",
    "# b. Correlation Analysis:\n",
    "# Check for correlations between features\n",
    "correlation_matrix = df_new_scaled.corr()\n",
    "\n",
    "# Plot a heatmap for correlation visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# c. Dimensionality Reduction (if needed) using PCA:\n",
    "# Assuming n_components is the number of principal components you want to keep\n",
    "n_components = len(selected_features)  # Adjust as needed\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the data\n",
    "principal_components = pca.fit_transform(df_new_scaled)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "columns_pca = [f\"PC{i + 1}\" for i in range(n_components)]\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=columns_pca)\n",
    "\n",
    "# Display the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio:\")\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "# Optionally, you can plot the cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "plt.plot(cumulative_explained_variance)\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.show()\n",
    "\n",
    "# Merge the principal components with the original DataFrame if needed\n",
    "df_filtered_pca = pd.concat([df_new_scaled, df_pca], axis=1)\n",
    "\n",
    "# Optionally, you can further analyze the importance of each feature in the principal components\n",
    "feature_importance_pca = pca.components_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0f07dfdd6bc4523",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a DataFrame with the principal components\n",
    "columns_pca = [f\"PC{i + 1}\" for i in range(n_components)]\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=columns_pca)\n",
    "\n",
    "# Classify 'risk' feature based on the condition\n",
    "df_pca[\"risk_classified\"] = df_new[\"risk\"].apply(lambda x: 1 if x >= -6 else 0)\n",
    "\n",
    "# Create a 3D scatter plot using Plotly Express\n",
    "fig = px.scatter_3d(\n",
    "    df_pca,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=\"risk_classified\",\n",
    "    color_discrete_map={0: \"blue\", 1: \"red\"},\n",
    ")\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter Plot of Data Points in Principal Component Space\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Principal Component 1\",\n",
    "        yaxis_title=\"Principal Component 2\",\n",
    "        zaxis_title=\"Principal Component 3\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6bd47148ad2e32d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3b0fc856d342291b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
